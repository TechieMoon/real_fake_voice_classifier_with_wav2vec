{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOKlYljO3RKJjhmPAkyyX0U"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## 1. 구글 드라이브에서 마운틴하기"],"metadata":{"id":"nMFYXm-kYSEw"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ly6lHOa_X-MU"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"markdown","source":["## 2. 파일 경로 지정하기\n","\n","진짜 음성 데이터가 담긴 폴더: /content/drive/MyDrive/Colab Notebooks/wav2vec classification/real\n","\n","가짜 음성 데이터가 담긴 폴더: /content/drive/MyDrive/Colab Notebooks/wav2vec classification/fake\n","\n","본인의 구글 드라이브에 저장되어 있는 폴더로 수정해야 함"],"metadata":{"id":"z_NwQ7bMYb6i"}},{"cell_type":"markdown","source":["## 3. 데이터셋 미리 생성"],"metadata":{"id":"TCA3BLwfor3P"}},{"cell_type":"code","source":["# preprocess_dataset.py\n","!pip install fsspec==2024.10.0\n","!pip install transformers datasets\n","from datasets import Dataset\n","import torchaudio\n","from transformers import Wav2Vec2Processor\n","import os\n","from sklearn.model_selection import train_test_split\n","from datasets import load_dataset\n","import torch\n","\n","# 경로 설정 (각자 구글 드라이브에 저장되어 있는 폴더로 수정해야 함)\n","real_path = \"/content/drive/MyDrive/Colab Notebooks/wav2vec classification/real\"\n","fake_path = \"/content/drive/MyDrive/Colab Notebooks/wav2vec classification/fake\"\n","\n","# 데이터 로딩 함수\n","def load_data(folder_path, label, max_files=None):\n","    files = []\n","    labels = []\n","    for i, file in enumerate(os.listdir(folder_path)):\n","        if file.endswith('.wav'):\n","            files.append(os.path.join(folder_path, file))\n","            labels.append(label)\n","        if max_files is not None and i+1 >= max_files:\n","            break\n","    return files, labels\n","\n","# 필요한 경우 max_files 조정\n","half = 25000\n","\n","real_files, real_labels = load_data(real_path, 1, max_files=half)\n","fake_files, fake_labels = load_data(fake_path, 0, max_files=half)\n","\n","# 모든 데이터를 사용하고 싶으면 위의 두 줄 코드를 아래 두 줄 코드로 변경해야 함\n","# real_files, real_labels = load_data(real_path, 1)\n","# fake_files, fake_labels = load_data(fake_path, 0)\n","\n","all_files = real_files + fake_files\n","all_labels = real_labels + fake_label\n","\n","train_files, test_files, train_labels, test_labels = train_test_split(all_files, all_labels, test_size=0.2, random_state=42)\n","\n","model_name = \"facebook/wav2vec2-base\"\n","processor = Wav2Vec2Processor.from_pretrained(model_name)\n","\n","# 전처리 함수\n","def preprocess(file_path):\n","    speech, sample_rate = torchaudio.load(file_path)\n","    # 이미 16kHz로 맞춰져 있다고 가정\n","    inputs = processor(speech.squeeze().numpy(), sampling_rate=16000, return_tensors=\"pt\", padding=True)\n","    return {\n","        'input_values': inputs['input_values'][0],  # (batch 차원 제거)\n","    }\n","\n","# train 데이터셋\n","train_data = {'file_path': train_files, 'label': train_labels}\n","train_dataset = Dataset.from_dict(train_data)\n","train_dataset = train_dataset.map(lambda example: {\n","    **preprocess(example['file_path']),\n","    'label': example['label']\n","})\n","\n","# test 데이터셋\n","test_data = {'file_path': test_files, 'label': test_labels}\n","test_dataset = Dataset.from_dict(test_data)\n","test_dataset = test_dataset.map(lambda example: {\n","    **preprocess(example['file_path']),\n","    'label': example['label']\n","})\n","\n","# 전처리 완료된 dataset 저장\n","# 원하시는 경로로 변경 가능\n","train_dataset.save_to_disk(\"/content/drive/MyDrive/Colab Notebooks/wav2vec classification/train_dataset\")\n","test_dataset.save_to_disk(\"/content/drive/MyDrive/Colab Notebooks/wav2vec classification/test_dataset\")\n"],"metadata":{"id":"00Xc0XCkouq6"},"execution_count":null,"outputs":[]}]}